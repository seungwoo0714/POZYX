{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import scipy as sp\n",
    "import scipy.stats\n",
    "class GMM(object):\n",
    "    def __init__(self, X, k=2):\n",
    "        # dimension\n",
    "        X = np.asarray(X)\n",
    "        self.m = len(X)\n",
    "        self.n = 1\n",
    "        self.data = X.copy()\n",
    "        # number of mixtures\n",
    "        self.k = k\n",
    "        \n",
    "    def _init(self):\n",
    "        # init mixture means/sigmas\n",
    "        self.mean_arr = np.asmatrix(np.random.random((self.k, self.n)))\n",
    "        self.sigma_arr = np.array([np.asmatrix(np.identity(self.n)) for i in range(self.k)])\n",
    "        self.phi = np.ones(self.k)/self.k\n",
    "        self.w = np.asmatrix(np.empty((self.m, self.k), dtype=float))\n",
    "        #print(self.mean_arr)\n",
    "        #print(self.sigma_arr)\n",
    "    \n",
    "    def fit(self, tol=1e-4):\n",
    "        self._init()\n",
    "        num_iters = 0\n",
    "        ll = 1\n",
    "        previous_ll = 0\n",
    "        while(ll-previous_ll > tol):\n",
    "            previous_ll = self.loglikelihood()\n",
    "            self._fit()\n",
    "            num_iters += 1\n",
    "            ll = self.loglikelihood()\n",
    "            print('Iteration %d: log-likelihood is %.6f'%(num_iters, ll))\n",
    "        print('Terminate at %d-th iteration:log-likelihood is %.6f'%(num_iters, ll))\n",
    "    \n",
    "    def loglikelihood(self):\n",
    "        ll = 0\n",
    "        for i in range(self.m):\n",
    "            tmp = 0\n",
    "            for j in range(self.k):\n",
    "                #print(self.sigma_arr[j])\n",
    "                tmp += sp.stats.multivariate_normal.pdf(self.data[i, :], \n",
    "                                                        #self.mean_arr[j, :].A1, \n",
    "                                                        self.sigma_arr[j, :]) *\\\n",
    "                       self.phi[j]\n",
    "            ll += np.log(tmp) \n",
    "        return ll\n",
    "    \n",
    "    def _fit(self):\n",
    "        self.e_step()\n",
    "        self.m_step()\n",
    "        \n",
    "    def e_step(self):\n",
    "        # calculate w_j^{(i)}\n",
    "        for i in range(self.m):\n",
    "            den = 0\n",
    "            for j in range(self.k):\n",
    "                num = sp.stats.multivariate_normal.pdf(self.data[i, :], \n",
    "                                                       self.mean_arr[j].A1, \n",
    "                                                       self.sigma_arr[j]) *\\\n",
    "                      self.phi[j]\n",
    "                den += num\n",
    "                self.w[i, j] = num\n",
    "            self.w[i, :] /= den\n",
    "            assert self.w[i, :].sum() - 1 < 1e-4\n",
    "            \n",
    "    def m_step(self):\n",
    "        for j in range(self.k):\n",
    "            const = self.w[:, j].sum()\n",
    "            self.phi[j] = 1/self.m * const\n",
    "            _mu_j = np.zeros(self.n)\n",
    "            _sigma_j = np.zeros((self.n, self.n))\n",
    "            for i in range(self.m):\n",
    "                _mu_j += (self.data[i, :] * self.w[i, j])\n",
    "                _sigma_j += self.w[i, j] * ((self.data[i, :] - self.mean_arr[j, :]).T * (self.data[i, :] - self.mean_arr[j, :]))\n",
    "                #print((self.data[i, :] - self.mean_arr[j, :]).T * (self.data[i, :] - self.mean_arr[j, :]))\n",
    "            self.mean_arr[j] = _mu_j / const\n",
    "            self.sigma_arr[j] = _sigma_j / const\n",
    "        #print(self.sigma_arr)\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "bias = 0\n",
    "std = 1\n",
    "\n",
    "m,n = np.array([1,2])\n",
    "print(m)\n",
    "print(n)\n",
    "\n",
    "\n",
    "x = np.array([8,8])\n",
    "H = np.array([[0,0],[10,0],[0,10],[10,10]])\n",
    "d = x-H\n",
    "d = np.multiply(d,d)\n",
    "d = np.sqrt(d.sum(axis=1))\n",
    "\n",
    "d_col_1 = d[1]-d[0]\n",
    "d_col_2 = d[2]-d[0] \n",
    "d_col_3 = d[3]-d[0]\n",
    "real_arr = np.array([d_col_1,d_col_2,d_col_3])\n",
    "#print(real_arr)\n",
    "\n",
    "SAMPLE = 10\n",
    "zd_col_tmp_1 = d[1]-d[0] + np.random.normal(bias,std,1)\n",
    "zd_col_tmp_2 = d[2]-d[0] + np.random.normal(bias,std,1)\n",
    "zd_col_tmp_3 = d[3]-d[0] + np.random.normal(bias,std,1)\n",
    "X = np.array([zd_col_tmp_1,zd_col_tmp_2,zd_col_tmp_3])\n",
    "X = np.transpose(X)\n",
    "\n",
    "for i in range(1,SAMPLE + 1):\n",
    "    zd_col_1 = d[1]-d[0] + np.random.normal(bias,std,1)\n",
    "    zd_col_2 = d[2]-d[0] + np.random.normal(bias,std,1)\n",
    "    zd_col_3 = d[3]-d[0] + np.random.normal(bias,std,1)\n",
    "    mu_arr = np.array([zd_col_1,zd_col_2,zd_col_3])\n",
    "    #mu_arr = np.transpose(mu_arr)\n",
    "    X = np.append(X,mu_arr)\n",
    "    print(X)\n",
    "print(X.shape)\n",
    "#X = np.random.normal(loc=mu_arr[0], scale=1, size=SAMPLE)\n",
    "\n",
    "#for i, mu in enumerate(mu_arr[1:]):\n",
    "X = np.append(X, np.random.normal(loc=mu, scale=1, size=SAMPLE))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 4))\n",
    "sns.distplot(X[:SAMPLE], ax=ax, rug=True)\n",
    "sns.distplot(X[SAMPLE:SAMPLE*2], ax=ax, rug=True)\n",
    "sns.distplot(X[SAMPLE*2:], ax=ax, rug=True)\n",
    "\n",
    "gmm = GMM(X, 3)\n",
    "gmm.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
