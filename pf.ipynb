{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.265371836807271\n",
      "4.428689481915411\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "from numpy.random import uniform\n",
    "import scipy.stats\n",
    "\n",
    "def create_uniform_particles(x_range, y_range, N):\n",
    "    particles = np.empty((N, 2))\n",
    "    particles[:, 0] = uniform(x_range[0], x_range[1], size=N)\n",
    "    particles[:, 1] = uniform(y_range[0], y_range[1], size=N)\n",
    "    return particles\n",
    "\n",
    "def predict(particles, u, std, dt=1.):\n",
    "    N = len(particles)\n",
    "    dist = (u[0] * dt) + (np.random.randn(N) * std[0])\n",
    "    particles[:, 0] +=  dist\n",
    "    particles[:, 1] +=  dist\n",
    "    \n",
    "def update(particles, weights, z, R, landmarks):\n",
    "    weights.fill(1.)\n",
    "    for i, landmark in enumerate(landmarks):\n",
    "       \n",
    "        distance=np.power((particles[:,0] - landmark[0])**2 +(particles[:,1] - landmark[1])**2,0.5)\n",
    "        weights *= scipy.stats.norm(distance, R).pdf(z[i])\n",
    " \n",
    " \n",
    "    weights += 1.e-300 # avoid round-off to zero\n",
    "    weights /= sum(weights)\n",
    "    \n",
    "def neff(weights):\n",
    "    return 1. / np.sum(np.square(weights))\n",
    " \n",
    "def systematic_resample(weights):\n",
    "    N = len(weights)\n",
    "    positions = (np.arange(N) + np.random.random()) / N\n",
    " \n",
    "    indexes = np.zeros(N, 'i')\n",
    "    cumulative_sum = np.cumsum(weights)\n",
    "    i, j = 0, 0\n",
    "    while i < N and j<N:\n",
    "        if positions[i] < cumulative_sum[j]:\n",
    "            indexes[i] = j\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    return indexes\n",
    "    \n",
    "def estimate(particles, weights):\n",
    "    pos = particles[:, 0:1]\n",
    "    mean = np.average(pos, weights=weights, axis=0)\n",
    "    var = np.average((pos - mean)**2, weights=weights, axis=0)\n",
    "    return mean, var\n",
    " \n",
    "def resample_from_index(particles, weights, indexes):\n",
    "    particles[:] = particles[indexes]\n",
    "    weights[:] = weights[indexes]\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "center=np.array([[-10,-10]]) \n",
    "trajectory=np.zeros(shape=(0,2))\n",
    "x_range=np.array([0,15])\n",
    "y_range=np.array([0,15])\n",
    "x = 7.5\n",
    "y = 4.8\n",
    "#Number of partciles\n",
    "N=10000\n",
    "H = np.array([[7.54,0],[7.54,7.21],[14.14,0],[14.14,7.58]])\n",
    "H2 = np.matrix([[7.54,0],[7.54,7.21],[14.14,0],[14.14,7.58]])\n",
    "landmarks = H\n",
    "NL = len(landmarks)\n",
    "particles=create_uniform_particles(x_range, y_range, N)\n",
    "weights = np.array([1.0]*N)\n",
    "previous_x=1\n",
    "previous_y=1\n",
    "sensor_std_err=1\n",
    "k = 1\n",
    "\n",
    "while k<200:\n",
    "    global center\n",
    "    global trajectory\n",
    "    global previous_x\n",
    "    global previous_y\n",
    "    global zs\n",
    "\n",
    "    center=np.array([[x,y]])\n",
    "    trajectory=np.vstack((trajectory,np.array([x,y])))\n",
    "    #noise=sensorSigma * np.random.randn(1,2) + sensorMu\n",
    "\n",
    "    if previous_x >0:\n",
    "        distance=np.linalg.norm(np.array([[previous_x,previous_y]])-np.array([[x,y]]) ,axis=1)\n",
    "        std=np.array([1,1])\n",
    "        u=np.array([distance])\n",
    "        predict(particles, u, std, dt=1.)\n",
    "        zs = (np.linalg.norm(landmarks - center, axis=1) + (np.random.randn(NL) * sensor_std_err))\n",
    "        update(particles, weights, z=zs, R=1, landmarks=landmarks)\n",
    "\n",
    "        indexes = systematic_resample(weights)\n",
    "        resample_from_index(particles, weights, indexes)\n",
    "        k = k+1\n",
    "\n",
    "    previous_x=x\n",
    "    previous_y=y\n",
    "    \n",
    "print(particles[0,0])\n",
    "print(particles[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
